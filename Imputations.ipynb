{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119833, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading in each csv file for the years of customer data\n",
    "data = pd.read_csv('data (1) copy.csv', encoding = 'ISO-8859-1')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   #Prod                    Agent Label +ID        Created           ID  \\\n",
      "0    1.0      Church Bulletin 0011 (109398)  7/30/14 14:36  657917124.0   \n",
      "1    1.0  Benefits and More 4 Paid (143595)  10/5/15 19:15  658935850.0   \n",
      "2    1.0  Benefits and More 4 Paid (143595)   5/2/16 20:16  659370939.0   \n",
      "3    1.0  Benefits and More 4 Paid (143595)  4/22/16 19:55  659356995.0   \n",
      "4    1.0       Benefits and More 4 (116063)  7/28/16 16:01  659940549.0   \n",
      "\n",
      "    Income  Last Pay Amount  Last Pay Complete Last Pay Date  Last Pay Status  \\\n",
      "0  36250.0            34.95                1.0       8/25/14              1.0   \n",
      "1  36250.0            29.95                1.0       10/5/15              1.0   \n",
      "2  36250.0            29.95                1.0        5/2/16              1.0   \n",
      "3  36250.0            39.95                1.0       5/12/16              1.0   \n",
      "4  36250.0              NaN                NaN           NaN              NaN   \n",
      "\n",
      "  Last Pay Type  Pay Method State              Status  ZipCodeNew  \\\n",
      "0        Refund    Discover    MA   Returned <30 days      1001.0   \n",
      "1          Sale    Discover    MA  Returned < 90 days      1001.0   \n",
      "2          Sale        Visa    MA      Switched to LW      1001.0   \n",
      "3        Refund  MasterCard    MA   Returned <30 days      1001.0   \n",
      "4           NaN         ACH    ME      Order Canceled      1001.0   \n",
      "\n",
      "               Stage date_created time_created  \n",
      "0  Back in Inventory      7/30/14        14:36  \n",
      "1  Back in Inventory      10/5/15        19:15  \n",
      "2                NaN       5/2/16        20:16  \n",
      "3  Back in Inventory      4/22/16        19:55  \n",
      "4   Post Date Cancel      7/28/16        16:01  \n"
     ]
    }
   ],
   "source": [
    "# Spliting the Created column into two rows with the date and time as seperate columns\n",
    "data['date_created'], data['time_created'] = data['Created'].str.split(' ', 1).str\n",
    "\n",
    "# Printing out the first 5 rows of each column in the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the two new split columns into datetime objects\n",
    "data['date_created'] = pd.to_datetime(data['date_created'])\n",
    "data['Last Pay Date'] = pd.to_datetime(data['Last Pay Date'])\n",
    "\n",
    "# Taking the difference between the last pay date and the date the account was created \n",
    "# Using the dt.days function to calculate amount of days in between those dates\n",
    "data['days'] = (data['Last Pay Date'] - data['date_created']).dt.days\n",
    "\n",
    "# Dividing the number of days by 30 to get the number of months with the company\n",
    "data['months'] = data['days']/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the year from the date_created column to create a 'year' column\n",
    "data['year'] = pd.DatetimeIndex(data['date_created']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding up the 'months' and 'days' columns to the hundredth decimal place\n",
    "data['months'] = np.round(data['months'], 2)\n",
    "data['days'] = np.round(data['days'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119833 entries, 0 to 119832\n",
      "Data columns (total 20 columns):\n",
      "#Prod                119794 non-null float64\n",
      "Agent Label +ID      119832 non-null object\n",
      "Created              119832 non-null object\n",
      "ID                   119832 non-null float64\n",
      "Income               118524 non-null float64\n",
      "Last Pay Amount      113509 non-null float64\n",
      "Last Pay Complete    113509 non-null float64\n",
      "Last Pay Date        113509 non-null datetime64[ns]\n",
      "Last Pay Status      113509 non-null float64\n",
      "Last Pay Type        113288 non-null object\n",
      "Pay Method           118063 non-null object\n",
      "State                119832 non-null object\n",
      "Status               119832 non-null object\n",
      "ZipCodeNew           119832 non-null float64\n",
      "Stage                100142 non-null object\n",
      "date_created         119832 non-null datetime64[ns]\n",
      "time_created         119832 non-null object\n",
      "days                 113509 non-null float64\n",
      "months               113509 non-null float64\n",
      "year                 119832 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(10), object(8)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Showing the data types for each column\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the row 'Created' as it's redundant\n",
    "data.drop(['Created'], axis=1)\n",
    "\n",
    "# Changing the order of the columns in the dataset\n",
    "data = data[['ID', 'year', 'Agent Label +ID', 'date_created', 'time_created', 'Last Pay Date', 'Pay Method', \n",
    "             'State', 'ZipCodeNew','Last Pay Amount', 'Last Pay Complete', 'Last Pay Status', 'Last Pay Type', \n",
    "             '#Prod', 'Stage', 'Status', 'Income', 'days', 'months']]\n",
    "\n",
    "# Renaming the columns in the data.csv dataset\n",
    "data.columns = ['id', 'year', 'agent', 'date_created', 'time_created', 'lp_date', 'pay_method', 'state', 'zip_code',\n",
    "               'lp_amount', 'lp_complete', 'lp_status', 'lp_type', 'prod', 'stage', 'status', 'income', 'days', 'months']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imputations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 1\n",
      "year 1\n",
      "agent 1\n",
      "date_created 1\n",
      "time_created 1\n",
      "lp_date 6324\n",
      "pay_method 1770\n",
      "state 1\n",
      "zip_code 1\n",
      "lp_amount 6324\n",
      "lp_complete 6324\n",
      "lp_status 6324\n",
      "lp_type 6545\n",
      "prod 39\n",
      "stage 19691\n",
      "status 1\n",
      "income 1309\n",
      "days 6324\n",
      "months 6324\n"
     ]
    }
   ],
   "source": [
    "# Same code we used in Data Mining to calculate number of missing values per column\n",
    "\n",
    "# Creating an empty list for column names\n",
    "names = []\n",
    "\n",
    "# Creating an empty list for the number of null values in each column\n",
    "values = []\n",
    "\n",
    "# Checking for Missing Values\n",
    "for col in data.columns:\n",
    "    names.append(col)\n",
    "    values.append(data[col].isnull().sum())\n",
    "    print(names[-1],values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting customers for the years 2018 and 2019\n",
    "# Would not be an accurate representation of these customers since they mathematically have not reached 18 months yet\n",
    "data = data[~((data['status'] == 'Active') & (data['year'] == 2018))]\n",
    "data = data[~((data['status'] == 'Active') & (data['year'] == 2019))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the income column using the median of the income column\n",
    "# Filling in any null values or 0 income values from the US Household Income dataset\n",
    "data['income'] = data['income'].fillna(data['income'].median())\n",
    "data['income'] = data['income'].replace(0, data['income'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>agent</th>\n",
       "      <th>date_created</th>\n",
       "      <th>time_created</th>\n",
       "      <th>lp_date</th>\n",
       "      <th>pay_method</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>lp_amount</th>\n",
       "      <th>lp_complete</th>\n",
       "      <th>lp_status</th>\n",
       "      <th>lp_type</th>\n",
       "      <th>prod</th>\n",
       "      <th>stage</th>\n",
       "      <th>status</th>\n",
       "      <th>income</th>\n",
       "      <th>days</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>672438569.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Yasha - Pers1 (264925)</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>15:02</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>MA</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>79.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lost/Not Paid</td>\n",
       "      <td>Returned</td>\n",
       "      <td>74083.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>658994577.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Benefits and More 4 Paid (143595)</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>15:06</td>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>Discover</td>\n",
       "      <td>MA</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lost/Not Paid</td>\n",
       "      <td>Returned</td>\n",
       "      <td>51250.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>13.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>657917863.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Newspaper (109455)</td>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>15:50</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>MA</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>34.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Order Canceled</td>\n",
       "      <td>29243.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>657821337.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Hospital (109465)</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>14:53</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>MA</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>34.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Back in Inventory</td>\n",
       "      <td>Returned &lt; 90 days</td>\n",
       "      <td>29243.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>659119311.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Benefits and More 4 Paid (143595)</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>19:09</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>MA</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>39.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lost/Not Paid</td>\n",
       "      <td>Returned</td>\n",
       "      <td>29243.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>13.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    year                              agent date_created  \\\n",
       "7   672438569.0  2017.0             Yasha - Pers1 (264925)   2017-10-20   \n",
       "13  658994577.0  2015.0  Benefits and More 4 Paid (143595)   2015-10-28   \n",
       "16  657917863.0  2014.0                 Newspaper (109455)   2014-07-30   \n",
       "17  657821337.0  2014.0                  Hospital (109465)   2014-05-27   \n",
       "19  659119311.0  2015.0  Benefits and More 4 Paid (143595)   2015-12-22   \n",
       "\n",
       "   time_created    lp_date  pay_method state  zip_code  lp_amount  \\\n",
       "7         15:02 2018-02-09  MasterCard    MA    1002.0      79.90   \n",
       "13        15:06 2016-12-11    Discover    MA    1010.0      29.95   \n",
       "16        15:50 2014-09-30  MasterCard    MA    1013.0      34.95   \n",
       "17        14:53 2014-08-25  MasterCard    MA    1013.0      34.95   \n",
       "19        19:09 2017-02-01  MasterCard    MA    1013.0      39.95   \n",
       "\n",
       "    lp_complete  lp_status lp_type  prod              stage  \\\n",
       "7           1.0        0.0    Sale   1.0      Lost/Not Paid   \n",
       "13          1.0        1.0    Sale   1.0      Lost/Not Paid   \n",
       "16          1.0        1.0     NaN   1.0                NaN   \n",
       "17          1.0        0.0    Sale   1.0  Back in Inventory   \n",
       "19          1.0        0.0    Sale   1.0      Lost/Not Paid   \n",
       "\n",
       "                status   income   days  months  \n",
       "7             Returned  74083.0  112.0    3.73  \n",
       "13            Returned  51250.0  410.0   13.67  \n",
       "16      Order Canceled  29243.0   62.0    2.07  \n",
       "17  Returned < 90 days  29243.0   90.0    3.00  \n",
       "19            Returned  29243.0  407.0   13.57  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting rows that do not include a Last Pay Date since the customer never paid for a product\n",
    "data = data[pd.notnull(data['lp_date'])]\n",
    "\n",
    "# Deleting one row where the zip code was never given\n",
    "data = data[pd.notnull(data['zip_code'])]\n",
    "\n",
    "# Deleting rows of customers who do not live in the United States\n",
    "data = data[~data['state'].isin(['PR'])]\n",
    "data = data[~data['state'].isin(['NT'])]\n",
    "data = data[~data['state'].isin(['PE'])]\n",
    "data = data[~data['state'].isin(['BC'])]\n",
    "\n",
    "# Removing those customers who did not stay with the company over 1 month\n",
    "# The company would not have received a payment from these customers\n",
    "data = data[~(data['months'] < 1)]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "year 0\n",
      "agent 0\n",
      "date_created 0\n",
      "time_created 0\n",
      "lp_date 0\n",
      "pay_method 14\n",
      "state 0\n",
      "zip_code 0\n",
      "lp_amount 0\n",
      "lp_complete 0\n",
      "lp_status 0\n",
      "lp_type 19\n",
      "prod 0\n",
      "stage 2307\n",
      "status 0\n",
      "income 0\n",
      "days 0\n",
      "months 0\n"
     ]
    }
   ],
   "source": [
    "# Same code we used in Data Mining to calculate number of missing values per column\n",
    "\n",
    "# Creating an empty list for column names\n",
    "names = []\n",
    "\n",
    "# Creating an empty list for the number of null values in each column\n",
    "values = []\n",
    "\n",
    "# Checking for Missing Values\n",
    "for col in data.columns:\n",
    "    names.append(col)\n",
    "    values.append(data[col].isnull().sum())\n",
    "    print(names[-1],values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MasterCard' 'Discover' 'Visa' 'ACH' 'American Express' 'Paper_Check'\n",
      " 'Mastercard' nan 'Other' 'Maestro']\n",
      "credit card    45672\n",
      "ACH             8126\n",
      "paper check     1357\n",
      "Other             28\n",
      "Name: pay_method, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Binning categorical columns to larger groups\n",
    "# Printing unique values for columns\n",
    "print(data['pay_method'].unique())\n",
    "\n",
    "#Binning 'pay_method' into 4 groups: Credit card, ACH, Paper Check, & Other\n",
    "data['pay_method'] = data['pay_method'].replace({'Visa': 'credit card', 'MasterCard': 'credit card', \n",
    "                                                 'Discover': 'credit card', 'American Express': 'credit card',\n",
    "                                                'Mastercard': 'credit card', 'Maestro': 'credit card',\n",
    "                                                'Paper_Check': 'paper check', np.nan: 'Other'})  \n",
    "\n",
    "# Counting the number of instances for each value in the 'pay_method' column\n",
    "print(data['pay_method'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a binary code for whether a customer staying over 18 months or not\n",
    "# 1 = greater than 18 months, 0 = less than 18 months\n",
    "data['Y'] = np.where(data['months'] >= 10., 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Returned' 'Order Canceled' 'Returned < 90 days' 'Decline Cancel'\n",
      " 'Active' 'Returned <30 days' 'Decline' 'Returned to Sender' 'Deactivated'\n",
      " 'Restricted' 'Daily Decline' 'Duplicate' 'Switched to LW'\n",
      " 'Returned <60 Days' 'Suspend' 'In Process' 'Collections'\n",
      " 'Chargeback Received' 'Test']\n"
     ]
    }
   ],
   "source": [
    "# Printing out the unique values for the 'status' column to see what values need to be combined\n",
    "print(data['status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the status names to more general names\n",
    "data['status'] = data['status'].replace({'Returned <30 days': 'Returned_90', 'Decline Cancel': 'Decline',\n",
    "                                        'Order Canceled': 'Order Cancelled', 'Daily Decline': 'Decline', \n",
    "                                        'Returned <60 Days': 'Returned_90', 'Chargeback Received': 'Other',\n",
    "                                        'In Process': 'Other', 'Post Date': 'Other', 'Suspend': 'Other',\n",
    "                                        'Test': 'Other', 'Returned < 90 days': 'Returned_90'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'agent', 'date_created', 'time_created', 'lp_date',\n",
       "       'pay_method', 'state', 'zip_code', 'lp_amount', 'lp_complete',\n",
       "       'lp_status', 'lp_type', 'prod', 'stage', 'status', 'income', 'days',\n",
       "       'months', 'Y', 'pay_method_ACH', 'pay_method_Other',\n",
       "       'pay_method_credit card', 'pay_method_paper check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the method of one-hot encoding for the different forms of pay methods\n",
    "data = pd.concat([data, pd.get_dummies(data['pay_method'], prefix = 'pay_method')], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MA', 'TX', 'NY', 'ME', 'NC', 'MT', 'RI', 'NH', 'KY', 'VT', 'CT',\n",
       "       'PA', 'NJ', 'NM', 'CA', 'NE', 'VA', 'DE', 'DC', 'MD', 'WV', 'SC',\n",
       "       'WI', 'TN', 'GA', 'FL', 'LA', 'AL', 'MS', 'MI', 'KS', 'MO', 'OH',\n",
       "       'AR', 'IN', 'IA', 'ID', 'WA', 'MN', 'SD', 'ND', 'IL', 'AZ', 'OK',\n",
       "       'OR', 'CO', 'WY', 'UT', 'NV', 'HI', 'AK'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying all of the states in the 'states' column\n",
    "data.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping states into regions to avoid dimensionality problems when running the data in the models\n",
    "data['state'] = data.state.replace({'MA': 'north_east', 'TX': 'south', 'NY': 'north_east', 'CO': 'rocky', \n",
    "                                    'ME': 'north_east', 'PA': 'north_east', 'MT': 'rocky', 'NJ': 'north_east', \n",
    "                                    'CA': 'west', 'NC': 'south_east', 'RI': 'north_east','SC': 'south_east', \n",
    "                                    'NH': 'north_east', 'GA': 'south_east', 'FL': 'south_east', 'KY': 'central', \n",
    "                                    'OH': 'central', 'MI': 'central', 'VT': 'north_east', 'AL': 'south', 'WI': 'central', \n",
    "                                    'CT': 'north_east','IL': 'central', 'KS': 'central', 'VA': 'north_east', \n",
    "                                    'LA': 'south', 'NM': 'south', 'UT': 'rocky', 'NE': 'rocky', \n",
    "                                    'DE': 'north_east', 'DC': 'north_east', 'WA': 'west','MD': 'north_east', \n",
    "                                    'MN': 'central', 'NV': 'west', 'WV': 'central', 'AZ': 'west', 'TN': 'central',\n",
    "                                    'MS': 'south', 'HI': 'west', 'IN': 'central', 'MO': 'south', 'AK': 'west', \n",
    "                                    'AR': 'south', 'IA': 'central', 'ID': 'rocky', 'WY': 'rocky', 'SD': 'rocky', \n",
    "                                    'ND': 'rocky', 'OK': 'south', 'OR': 'west'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "north_east    12278\n",
       "south         11962\n",
       "south_east    10855\n",
       "central       10737\n",
       "west           7655\n",
       "rocky          1696\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prinitng out the new state bins to make sure no states were omitted in the replace dictionary\n",
    "data.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'agent', 'date_created', 'time_created', 'lp_date',\n",
       "       'pay_method', 'state', 'zip_code', 'lp_amount', 'lp_complete',\n",
       "       'lp_status', 'lp_type', 'prod', 'stage', 'status', 'income', 'days',\n",
       "       'months', 'Y', 'pay_method_ACH', 'pay_method_Other',\n",
       "       'pay_method_credit card', 'pay_method_paper check', 'region_central',\n",
       "       'region_north_east', 'region_rocky', 'region_south',\n",
       "       'region_south_east', 'region_west'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the method of one-hot encoding for the different regions\n",
    "data = pd.concat([data, pd.get_dummies(data['state'], prefix = 'region')], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'agent', 'date_created', 'time_created', 'lp_date',\n",
       "       'pay_method', 'state', 'zip_code', 'lp_amount', 'lp_complete',\n",
       "       'lp_status', 'lp_type', 'prod', 'stage', 'status', 'income', 'days',\n",
       "       'months', 'Y', 'pay_method_ACH', 'pay_method_Other',\n",
       "       'pay_method_credit card', 'pay_method_paper check', 'region_central',\n",
       "       'region_north_east', 'region_rocky', 'region_south',\n",
       "       'region_south_east', 'region_west', 'status_Active',\n",
       "       'status_Collections', 'status_Deactivated', 'status_Decline',\n",
       "       'status_Duplicate', 'status_Order Cancelled', 'status_Other',\n",
       "       'status_Restricted', 'status_Returned', 'status_Returned to Sender',\n",
       "       'status_Returned_90', 'status_Switched to LW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the method of one-hot encoding for the different status types\n",
    "data = pd.concat([data, pd.get_dummies(data['status'], prefix = 'status')], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'agent', 'pay_method', 'state', 'zip_code', 'status', 'income',\n",
       "       'months', 'Y', 'pay_method_ACH', 'pay_method_credit card',\n",
       "       'pay_method_paper check', 'region_central', 'region_north_east',\n",
       "       'region_rocky', 'region_south', 'region_south_east', 'region_west',\n",
       "       'status_Active', 'status_Decline', 'status_Returned',\n",
       "       'status_Returned_90', 'status_Switched to LW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping columns we will not be using in the models\n",
    "data = data.drop(['id', 'date_created', 'time_created', 'lp_date','days', 'lp_complete', 'lp_status', 'lp_type', \n",
    "                  'prod', 'stage', 'lp_amount',  'status_Collections', 'status_Deactivated', 'status_Duplicate', \n",
    "                  'status_Order Cancelled', 'status_Other', 'status_Restricted', 'status_Returned to Sender', \n",
    "                  'pay_method_Other'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year                              agent   pay_method       state  \\\n",
      "7   2017.0             Yasha - Pers1 (264925)  credit card  north_east   \n",
      "13  2015.0  Benefits and More 4 Paid (143595)  credit card  north_east   \n",
      "16  2014.0                 Newspaper (109455)  credit card  north_east   \n",
      "17  2014.0                  Hospital (109465)  credit card  north_east   \n",
      "19  2015.0  Benefits and More 4 Paid (143595)  credit card  north_east   \n",
      "\n",
      "    zip_code           status   income  months  Y  pay_method_ACH  \\\n",
      "7     1002.0         Returned  74083.0    3.73  0               0   \n",
      "13    1010.0         Returned  51250.0   13.67  1               0   \n",
      "16    1013.0  Order Cancelled  29243.0    2.07  0               0   \n",
      "17    1013.0      Returned_90  29243.0    3.00  0               0   \n",
      "19    1013.0         Returned  29243.0   13.57  1               0   \n",
      "\n",
      "            ...            region_north_east  region_rocky  region_south  \\\n",
      "7           ...                            1             0             0   \n",
      "13          ...                            1             0             0   \n",
      "16          ...                            1             0             0   \n",
      "17          ...                            1             0             0   \n",
      "19          ...                            1             0             0   \n",
      "\n",
      "    region_south_east  region_west  status_Active  status_Decline  \\\n",
      "7                   0            0              0               0   \n",
      "13                  0            0              0               0   \n",
      "16                  0            0              0               0   \n",
      "17                  0            0              0               0   \n",
      "19                  0            0              0               0   \n",
      "\n",
      "    status_Returned  status_Returned_90  status_Switched to LW  \n",
      "7                 1                   0                      0  \n",
      "13                1                   0                      0  \n",
      "16                0                   0                      0  \n",
      "17                0                   1                      0  \n",
      "19                1                   0                      0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(55183, 23)\n"
     ]
    }
   ],
   "source": [
    "# Calling data.head() to view the data and the dimensions of the new dataset\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 0\n",
      "agent 0\n",
      "pay_method 0\n",
      "state 0\n",
      "zip_code 0\n",
      "status 0\n",
      "income 0\n",
      "months 0\n",
      "Y 0\n",
      "pay_method_ACH 0\n",
      "pay_method_credit card 0\n",
      "pay_method_paper check 0\n",
      "region_central 0\n",
      "region_north_east 0\n",
      "region_rocky 0\n",
      "region_south 0\n",
      "region_south_east 0\n",
      "region_west 0\n",
      "status_Active 0\n",
      "status_Decline 0\n",
      "status_Returned 0\n",
      "status_Returned_90 0\n",
      "status_Switched to LW 0\n"
     ]
    }
   ],
   "source": [
    "# Same code we used in Data Mining to calculate number of missing values per column\n",
    "\n",
    "# Creating an empty list for column names\n",
    "names = []\n",
    "\n",
    "# Creating an empty list for the number of null values in each column\n",
    "values = []\n",
    "\n",
    "# Checking for Missing Values\n",
    "for col in data.columns:\n",
    "    names.append(col)\n",
    "    values.append(data[col].isnull().sum())\n",
    "    print(names[-1],values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the imputed data as impute_data.csv to begin normalization\n",
    "data.to_csv('imputed_data.csv',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
